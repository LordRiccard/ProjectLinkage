{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2012.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2013.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2014.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2015.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2016.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2017.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2018.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2019.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2020.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2021.csv', 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1\\\\DN2022.csv']\n"
     ]
    }
   ],
   "source": [
    "directory = 'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - FINAL 1'\n",
    "pattern = f'*.csv'\n",
    "\n",
    "files = glob.glob(f'{directory}/{pattern}')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2012.csv - tamanho 3197707\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2012.csv - novo tamanho 3197707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2013.csv - tamanho 3197575\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2013.csv - novo tamanho 3197575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2014.csv - tamanho 3282309\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2014.csv - novo tamanho 3282309\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2015.csv - tamanho 3311296\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2015.csv - novo tamanho 3311296\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2016.csv - tamanho 3149750\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2016.csv - novo tamanho 3149750\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2017.csv - tamanho 3216411\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2017.csv - novo tamanho 3216411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2018.csv - tamanho 3232183\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2018.csv - novo tamanho 3232183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2019.csv - tamanho 3139558\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2019.csv - novo tamanho 3139558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2020.csv - tamanho 3013130\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2020.csv - novo tamanho 3013130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2021.csv - tamanho 2951464\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2021.csv - novo tamanho 2951464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3799559693.py:3: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2022.csv - tamanho 2856466\n",
      "D:\\_repositories\\Aggregation\\Results\\SINASC - FINAL 1\\DN2022.csv - novo tamanho 2856466\n"
     ]
    }
   ],
   "source": [
    "i = 2012\n",
    "for item in files:\n",
    "    df = pd.read_csv(item)\n",
    "\n",
    "    for colunas in df.columns:\n",
    "        try:\n",
    "            df[colunas] = df[colunas].astype('Int64')\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    print(f'{item} - tamanho {len(df)}')\n",
    "    df = df.drop_duplicates()\n",
    "    print(f'{item} - novo tamanho {len(df)}')\n",
    "    \n",
    "    df.to_csv(f'D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN{i}.csv',\n",
    "              index=False)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\2045166467.py:2: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2013.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3197575 entries, 0 to 3197574\n",
      "Data columns (total 60 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   contador    int64  \n",
      " 2   ORIGEM      int64  \n",
      " 3   CODCART     float64\n",
      " 4   CODMUNCART  int64  \n",
      " 5   NUMREGCART  float64\n",
      " 6   DTREGCART   float64\n",
      " 7   CODESTAB    float64\n",
      " 8   CODMUNNASC  int64  \n",
      " 9   LOCNASC     int64  \n",
      " 10  IDADEMAE    float64\n",
      " 11  ESTCIVMAE   float64\n",
      " 12  ESCMAE      float64\n",
      " 13  CODOCUPMAE  float64\n",
      " 14  QTDFILVIVO  float64\n",
      " 15  QTDFILMORT  float64\n",
      " 16  CODMUNRES   int64  \n",
      " 17  CODPAISRES  float64\n",
      " 18  GRAVIDEZ    float64\n",
      " 19  PARTO       float64\n",
      " 20  CONSULTAS   float64\n",
      " 21  DTNASC      int64  \n",
      " 22  HORANASC    float64\n",
      " 23  SEXO        int64  \n",
      " 24  APGAR1      float64\n",
      " 25  APGAR5      float64\n",
      " 26  RACACORN    float64\n",
      " 27  RACACORMAE  float64\n",
      " 28  RACACOR     float64\n",
      " 29  PESO        float64\n",
      " 30  IDANOMAL    float64\n",
      " 31  CODANOMAL   object \n",
      " 32  DTCADASTRO  float64\n",
      " 33  NUMEROLOTE  float64\n",
      " 34  VERSAOSIST  object \n",
      " 35  DTRECEBIM   float64\n",
      " 36  DTRECORIG   float64\n",
      " 37  DIFDATA     int64  \n",
      " 38  NATURALMAE  float64\n",
      " 39  CODMUNNATU  float64\n",
      " 40  CODUFNATU   float64\n",
      " 41  DTNASCMAE   float64\n",
      " 42  QTDGESTANT  float64\n",
      " 43  QTDPARTNOR  float64\n",
      " 44  QTDPARTCES  float64\n",
      " 45  IDADEPAI    object \n",
      " 46  DTULTMENST  float64\n",
      " 47  MESPRENAT   float64\n",
      " 48  TPAPRESENT  float64\n",
      " 49  STTRABPART  float64\n",
      " 50  STCESPARTO  float64\n",
      " 51  TPNASCASSI  float64\n",
      " 52  STDNEPIDEM  float64\n",
      " 53  STDNNOVA    int64  \n",
      " 54  SERIESCMAE  float64\n",
      " 55  ESCMAEAGR1  float64\n",
      " 56  SEMAGESTAC  float64\n",
      " 57  GESTACAO    float64\n",
      " 58  TPMETESTIM  float64\n",
      " 59  ESCMAE2010  float64\n",
      "dtypes: float64(46), int64(11), object(3)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "# 45\n",
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2013.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1528029847.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['IDADEPAI'].loc[df['IDADEPAI'] == '5D'] = 50\n",
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1528029847.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['IDADEPAI'].loc[df['IDADEPAI'] == '5D'] = 50\n"
     ]
    }
   ],
   "source": [
    "df['IDADEPAI'].loc[df['IDADEPAI'] == '5D'] = 50\n",
    "\n",
    "df['IDADEPAI'] = df['IDADEPAI'].astype('Float64')\n",
    "df['IDADEPAI'] = df['IDADEPAI'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2013.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2013.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1995237685.py:1: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2014.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3282309 entries, 0 to 3282308\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   contador    int64  \n",
      " 2   ORIGEM      int64  \n",
      " 3   CODESTAB    float64\n",
      " 4   CODMUNNASC  int64  \n",
      " 5   LOCNASC     int64  \n",
      " 6   IDADEMAE    float64\n",
      " 7   ESTCIVMAE   float64\n",
      " 8   ESCMAE      float64\n",
      " 9   CODOCUPMAE  float64\n",
      " 10  QTDFILVIVO  float64\n",
      " 11  QTDFILMORT  float64\n",
      " 12  CODMUNRES   int64  \n",
      " 13  GESTACAO    float64\n",
      " 14  GRAVIDEZ    float64\n",
      " 15  PARTO       float64\n",
      " 16  CONSULTAS   float64\n",
      " 17  DTNASC      int64  \n",
      " 18  HORANASC    object \n",
      " 19  SEXO        object \n",
      " 20  APGAR1      float64\n",
      " 21  APGAR5      float64\n",
      " 22  RACACOR     float64\n",
      " 23  PESO        float64\n",
      " 24  IDANOMAL    float64\n",
      " 25  DTCADASTRO  float64\n",
      " 26  CODANOMAL   object \n",
      " 27  NUMEROLOTE  float64\n",
      " 28  VERSAOSIST  object \n",
      " 29  DTRECEBIM   float64\n",
      " 30  DIFDATA     float64\n",
      " 31  DTRECORIGA  float64\n",
      " 32  NATURALMAE  float64\n",
      " 33  CODMUNNATU  float64\n",
      " 34  CODUFNATU   float64\n",
      " 35  ESCMAE2010  float64\n",
      " 36  SERIESCMAE  float64\n",
      " 37  DTNASCMAE   float64\n",
      " 38  RACACORMAE  float64\n",
      " 39  QTDGESTANT  float64\n",
      " 40  QTDPARTNOR  float64\n",
      " 41  QTDPARTCES  float64\n",
      " 42  IDADEPAI    float64\n",
      " 43  DTULTMENST  float64\n",
      " 44  SEMAGESTAC  float64\n",
      " 45  TPMETESTIM  float64\n",
      " 46  CONSPRENAT  float64\n",
      " 47  MESPRENAT   float64\n",
      " 48  TPAPRESENT  float64\n",
      " 49  STTRABPART  float64\n",
      " 50  STCESPARTO  float64\n",
      " 51  TPNASCASSI  float64\n",
      " 52  TPFUNCRESP  float64\n",
      " 53  TPDOCRESP   float64\n",
      " 54  DTDECLARAC  float64\n",
      " 55  ESCMAEAGR1  float64\n",
      " 56  STDNEPIDEM  float64\n",
      " 57  STDNNOVA    float64\n",
      " 58  CODPAISRES  float64\n",
      " 59  TPROBSON    int64  \n",
      " 60  PARIDADE    int64  \n",
      " 61  KOTELCHUCK  int64  \n",
      "dtypes: float64(48), int64(10), object(4)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2014.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['HORANASC'].loc[df['HORANASC'] == '10;05'] = 1005\n",
    "# df['HORANASC'].loc[df['HORANASC'] == '10;55'] = 1055\n",
    "# df['HORANASC'].loc[df['HORANASC'] == '20;50'] = 2050\n",
    "# df['HORANASC'].loc[df['HORANASC'] == '20;50'] = 2050\n",
    "\n",
    "df['HORANASC'] = df['HORANASC'].astype(str)\n",
    "df['HORANASC'] = df['HORANASC'].apply(lambda x: x.replace(';', ''))\n",
    "df['HORANASC'] = df['HORANASC'].apply(lambda x: x.replace('/', ''))\n",
    "df['HORANASC'] = df['HORANASC'].apply(lambda x: x.replace('-', ''))\n",
    "df['HORANASC'] = df['HORANASC'].apply(lambda x: x.replace('?', ''))\n",
    "df['HORANASC'] = df['HORANASC'].apply(lambda x: x.replace('>', ''))\n",
    "\n",
    "df['HORANASC'] = df['HORANASC'].astype('Float64')\n",
    "df['HORANASC'] = df['HORANASC'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2014.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2014.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\293434260.py:1: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2018.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3232183 entries, 0 to 3232182\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   ORIGEM      int64  \n",
      " 2   CODESTAB    float64\n",
      " 3   CODMUNNASC  int64  \n",
      " 4   LOCNASC     int64  \n",
      " 5   IDADEMAE    float64\n",
      " 6   ESTCIVMAE   float64\n",
      " 7   ESCMAE      float64\n",
      " 8   CODOCUPMAE  float64\n",
      " 9   QTDFILVIVO  float64\n",
      " 10  QTDFILMORT  float64\n",
      " 11  CODMUNRES   int64  \n",
      " 12  GESTACAO    float64\n",
      " 13  GRAVIDEZ    float64\n",
      " 14  PARTO       float64\n",
      " 15  CONSULTAS   float64\n",
      " 16  DTNASC      int64  \n",
      " 17  HORANASC    float64\n",
      " 18  SEXO        int64  \n",
      " 19  APGAR1      float64\n",
      " 20  APGAR5      float64\n",
      " 21  RACACOR     float64\n",
      " 22  PESO        float64\n",
      " 23  IDANOMAL    float64\n",
      " 24  DTCADASTRO  int64  \n",
      " 25  CODANOMAL   object \n",
      " 26  NUMEROLOTE  float64\n",
      " 27  VERSAOSIST  object \n",
      " 28  DTRECEBIM   float64\n",
      " 29  DIFDATA     int64  \n",
      " 30  DTRECORIGA  float64\n",
      " 31  NATURALMAE  float64\n",
      " 32  CODMUNNATU  float64\n",
      " 33  CODUFNATU   object \n",
      " 34  ESCMAE2010  float64\n",
      " 35  SERIESCMAE  float64\n",
      " 36  DTNASCMAE   float64\n",
      " 37  RACACORMAE  float64\n",
      " 38  QTDGESTANT  float64\n",
      " 39  QTDPARTNOR  float64\n",
      " 40  QTDPARTCES  float64\n",
      " 41  IDADEPAI    float64\n",
      " 42  DTULTMENST  float64\n",
      " 43  SEMAGESTAC  float64\n",
      " 44  TPMETESTIM  float64\n",
      " 45  CONSPRENAT  float64\n",
      " 46  MESPRENAT   float64\n",
      " 47  TPAPRESENT  float64\n",
      " 48  STTRABPART  float64\n",
      " 49  STCESPARTO  float64\n",
      " 50  TPNASCASSI  float64\n",
      " 51  TPFUNCRESP  float64\n",
      " 52  TPDOCRESP   float64\n",
      " 53  DTDECLARAC  float64\n",
      " 54  ESCMAEAGR1  float64\n",
      " 55  STDNEPIDEM  float64\n",
      " 56  STDNNOVA    int64  \n",
      " 57  CODPAISRES  float64\n",
      " 58  TPROBSON    int64  \n",
      " 59  PARIDADE    int64  \n",
      " 60  KOTELCHUCK  int64  \n",
      " 61  CONTADOR    int64  \n",
      "dtypes: float64(45), int64(14), object(3)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2018.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
    "\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Float64')\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2018.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2018.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_22576\\3045327033.py:1: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2019.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3139558 entries, 0 to 3139557\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   ORIGEM      int64  \n",
      " 2   CODESTAB    float64\n",
      " 3   CODMUNNASC  int64  \n",
      " 4   LOCNASC     int64  \n",
      " 5   IDADEMAE    float64\n",
      " 6   ESTCIVMAE   float64\n",
      " 7   ESCMAE      float64\n",
      " 8   CODOCUPMAE  float64\n",
      " 9   QTDFILVIVO  float64\n",
      " 10  QTDFILMORT  float64\n",
      " 11  CODMUNRES   int64  \n",
      " 12  GESTACAO    float64\n",
      " 13  GRAVIDEZ    float64\n",
      " 14  PARTO       float64\n",
      " 15  CONSULTAS   float64\n",
      " 16  DTNASC      int64  \n",
      " 17  HORANASC    float64\n",
      " 18  SEXO        int64  \n",
      " 19  APGAR1      float64\n",
      " 20  APGAR5      float64\n",
      " 21  RACACOR     float64\n",
      " 22  PESO        float64\n",
      " 23  IDANOMAL    float64\n",
      " 24  DTCADASTRO  int64  \n",
      " 25  CODANOMAL   object \n",
      " 26  NUMEROLOTE  float64\n",
      " 27  VERSAOSIST  object \n",
      " 28  DTRECEBIM   float64\n",
      " 29  DIFDATA     int64  \n",
      " 30  DTRECORIGA  float64\n",
      " 31  NATURALMAE  float64\n",
      " 32  CODMUNNATU  float64\n",
      " 33  CODUFNATU   object \n",
      " 34  ESCMAE2010  float64\n",
      " 35  SERIESCMAE  float64\n",
      " 36  DTNASCMAE   float64\n",
      " 37  RACACORMAE  float64\n",
      " 38  QTDGESTANT  float64\n",
      " 39  QTDPARTNOR  float64\n",
      " 40  QTDPARTCES  float64\n",
      " 41  IDADEPAI    float64\n",
      " 42  DTULTMENST  float64\n",
      " 43  SEMAGESTAC  float64\n",
      " 44  TPMETESTIM  float64\n",
      " 45  CONSPRENAT  float64\n",
      " 46  MESPRENAT   float64\n",
      " 47  TPAPRESENT  float64\n",
      " 48  STTRABPART  float64\n",
      " 49  STCESPARTO  float64\n",
      " 50  TPNASCASSI  float64\n",
      " 51  TPFUNCRESP  float64\n",
      " 52  TPDOCRESP   float64\n",
      " 53  DTDECLARAC  float64\n",
      " 54  ESCMAEAGR1  float64\n",
      " 55  STDNEPIDEM  float64\n",
      " 56  STDNNOVA    int64  \n",
      " 57  CODPAISRES  float64\n",
      " 58  TPROBSON    int64  \n",
      " 59  PARIDADE    int64  \n",
      " 60  KOTELCHUCK  int64  \n",
      " 61  CONTADOR    int64  \n",
      "dtypes: float64(45), int64(14), object(3)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2019.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_22576\\1792415848.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_22576\\1792415848.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
    "\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Float64')\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2019.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2019.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\2909146483.py:1: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2020.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3013130 entries, 0 to 3013129\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   ORIGEM      int64  \n",
      " 2   CODESTAB    float64\n",
      " 3   CODMUNNASC  int64  \n",
      " 4   LOCNASC     int64  \n",
      " 5   IDADEMAE    float64\n",
      " 6   ESTCIVMAE   float64\n",
      " 7   ESCMAE      float64\n",
      " 8   CODOCUPMAE  float64\n",
      " 9   QTDFILVIVO  float64\n",
      " 10  QTDFILMORT  float64\n",
      " 11  CODMUNRES   int64  \n",
      " 12  GESTACAO    float64\n",
      " 13  GRAVIDEZ    float64\n",
      " 14  PARTO       float64\n",
      " 15  CONSULTAS   float64\n",
      " 16  DTNASC      int64  \n",
      " 17  HORANASC    float64\n",
      " 18  SEXO        int64  \n",
      " 19  APGAR1      float64\n",
      " 20  APGAR5      float64\n",
      " 21  RACACOR     float64\n",
      " 22  PESO        float64\n",
      " 23  IDANOMAL    float64\n",
      " 24  DTCADASTRO  int64  \n",
      " 25  CODANOMAL   object \n",
      " 26  NUMEROLOTE  float64\n",
      " 27  VERSAOSIST  object \n",
      " 28  DTRECEBIM   float64\n",
      " 29  DIFDATA     int64  \n",
      " 30  DTRECORIGA  float64\n",
      " 31  NATURALMAE  float64\n",
      " 32  CODMUNNATU  float64\n",
      " 33  CODUFNATU   object \n",
      " 34  ESCMAE2010  float64\n",
      " 35  SERIESCMAE  float64\n",
      " 36  DTNASCMAE   float64\n",
      " 37  RACACORMAE  float64\n",
      " 38  QTDGESTANT  float64\n",
      " 39  QTDPARTNOR  float64\n",
      " 40  QTDPARTCES  float64\n",
      " 41  IDADEPAI    float64\n",
      " 42  DTULTMENST  float64\n",
      " 43  SEMAGESTAC  float64\n",
      " 44  TPMETESTIM  float64\n",
      " 45  CONSPRENAT  float64\n",
      " 46  MESPRENAT   float64\n",
      " 47  TPAPRESENT  float64\n",
      " 48  STTRABPART  float64\n",
      " 49  STCESPARTO  float64\n",
      " 50  TPNASCASSI  float64\n",
      " 51  TPFUNCRESP  float64\n",
      " 52  TPDOCRESP   float64\n",
      " 53  DTDECLARAC  float64\n",
      " 54  ESCMAEAGR1  float64\n",
      " 55  STDNEPIDEM  float64\n",
      " 56  STDNNOVA    int64  \n",
      " 57  CODPAISRES  float64\n",
      " 58  TPROBSON    int64  \n",
      " 59  PARIDADE    int64  \n",
      " 60  KOTELCHUCK  int64  \n",
      " 61  CONTADOR    int64  \n",
      "dtypes: float64(45), int64(14), object(3)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2020.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
    "\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Float64')\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2020.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2020.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\3864261357.py:1: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2021.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2951464 entries, 0 to 2951463\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   ORIGEM      int64  \n",
      " 2   CODESTAB    float64\n",
      " 3   CODMUNNASC  int64  \n",
      " 4   LOCNASC     int64  \n",
      " 5   IDADEMAE    float64\n",
      " 6   ESTCIVMAE   float64\n",
      " 7   ESCMAE      float64\n",
      " 8   CODOCUPMAE  float64\n",
      " 9   QTDFILVIVO  float64\n",
      " 10  QTDFILMORT  float64\n",
      " 11  CODMUNRES   int64  \n",
      " 12  GESTACAO    float64\n",
      " 13  GRAVIDEZ    float64\n",
      " 14  PARTO       float64\n",
      " 15  CONSULTAS   float64\n",
      " 16  DTNASC      int64  \n",
      " 17  HORANASC    float64\n",
      " 18  SEXO        int64  \n",
      " 19  APGAR1      float64\n",
      " 20  APGAR5      float64\n",
      " 21  RACACOR     float64\n",
      " 22  PESO        float64\n",
      " 23  IDANOMAL    float64\n",
      " 24  DTCADASTRO  int64  \n",
      " 25  CODANOMAL   object \n",
      " 26  NUMEROLOTE  float64\n",
      " 27  VERSAOSIST  object \n",
      " 28  DTRECEBIM   float64\n",
      " 29  DIFDATA     int64  \n",
      " 30  DTRECORIGA  float64\n",
      " 31  NATURALMAE  float64\n",
      " 32  CODMUNNATU  float64\n",
      " 33  CODUFNATU   object \n",
      " 34  ESCMAE2010  float64\n",
      " 35  SERIESCMAE  float64\n",
      " 36  DTNASCMAE   float64\n",
      " 37  RACACORMAE  float64\n",
      " 38  QTDGESTANT  float64\n",
      " 39  QTDPARTNOR  float64\n",
      " 40  QTDPARTCES  float64\n",
      " 41  IDADEPAI    float64\n",
      " 42  DTULTMENST  float64\n",
      " 43  SEMAGESTAC  float64\n",
      " 44  TPMETESTIM  float64\n",
      " 45  CONSPRENAT  float64\n",
      " 46  MESPRENAT   float64\n",
      " 47  TPAPRESENT  float64\n",
      " 48  STTRABPART  float64\n",
      " 49  STCESPARTO  float64\n",
      " 50  TPNASCASSI  float64\n",
      " 51  TPFUNCRESP  float64\n",
      " 52  TPDOCRESP   float64\n",
      " 53  DTDECLARAC  float64\n",
      " 54  ESCMAEAGR1  float64\n",
      " 55  STDNEPIDEM  float64\n",
      " 56  STDNNOVA    int64  \n",
      " 57  CODPAISRES  float64\n",
      " 58  TPROBSON    int64  \n",
      " 59  PARIDADE    int64  \n",
      " 60  KOTELCHUCK  int64  \n",
      " 61  CONTADOR    int64  \n",
      "dtypes: float64(45), int64(14), object(3)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2021.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
    "\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Float64')\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2021.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2021.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1415080756.py:1: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2022.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2856466 entries, 0 to 2856465\n",
      "Data columns (total 62 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   ORIGEM      int64  \n",
      " 2   CODESTAB    float64\n",
      " 3   CODMUNNASC  int64  \n",
      " 4   LOCNASC     int64  \n",
      " 5   IDADEMAE    float64\n",
      " 6   ESTCIVMAE   float64\n",
      " 7   ESCMAE      float64\n",
      " 8   CODOCUPMAE  float64\n",
      " 9   QTDFILVIVO  float64\n",
      " 10  QTDFILMORT  float64\n",
      " 11  CODMUNRES   int64  \n",
      " 12  GESTACAO    float64\n",
      " 13  GRAVIDEZ    float64\n",
      " 14  PARTO       float64\n",
      " 15  CONSULTAS   float64\n",
      " 16  DTNASC      int64  \n",
      " 17  HORANASC    float64\n",
      " 18  SEXO        int64  \n",
      " 19  APGAR1      float64\n",
      " 20  APGAR5      float64\n",
      " 21  RACACOR     float64\n",
      " 22  PESO        float64\n",
      " 23  IDANOMAL    float64\n",
      " 24  DTCADASTRO  int64  \n",
      " 25  CODANOMAL   object \n",
      " 26  NUMEROLOTE  float64\n",
      " 27  VERSAOSIST  object \n",
      " 28  DTRECEBIM   float64\n",
      " 29  DIFDATA     int64  \n",
      " 30  DTRECORIGA  float64\n",
      " 31  NATURALMAE  float64\n",
      " 32  CODMUNNATU  float64\n",
      " 33  CODUFNATU   object \n",
      " 34  ESCMAE2010  float64\n",
      " 35  SERIESCMAE  float64\n",
      " 36  DTNASCMAE   float64\n",
      " 37  RACACORMAE  float64\n",
      " 38  QTDGESTANT  float64\n",
      " 39  QTDPARTNOR  float64\n",
      " 40  QTDPARTCES  float64\n",
      " 41  IDADEPAI    float64\n",
      " 42  DTULTMENST  float64\n",
      " 43  SEMAGESTAC  float64\n",
      " 44  TPMETESTIM  float64\n",
      " 45  CONSPRENAT  float64\n",
      " 46  MESPRENAT   float64\n",
      " 47  TPAPRESENT  float64\n",
      " 48  STTRABPART  float64\n",
      " 49  STCESPARTO  float64\n",
      " 50  TPNASCASSI  float64\n",
      " 51  TPFUNCRESP  float64\n",
      " 52  TPDOCRESP   float64\n",
      " 53  DTDECLARAC  float64\n",
      " 54  ESCMAEAGR1  float64\n",
      " 55  STDNEPIDEM  float64\n",
      " 56  STDNNOVA    int64  \n",
      " 57  CODPAISRES  float64\n",
      " 58  TPROBSON    int64  \n",
      " 59  PARIDADE    int64  \n",
      " 60  KOTELCHUCK  int64  \n",
      " 61  CONTADOR    int64  \n",
      "dtypes: float64(45), int64(14), object(3)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Tipos Melhor\\\\DN2022.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_7408\\1792415848.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "df['CODUFNATU'].loc[df['CODUFNATU'] == 'nu'] = pd.NA\n",
    "\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Float64')\n",
    "df['CODUFNATU'] = df['CODUFNATU'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colunas in df.columns:\n",
    "    try:\n",
    "        df[colunas] = df[colunas].astype('Int64')\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2022.csv', index=False)\n",
    "df.to_parquet('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2022.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricmo\\AppData\\Local\\Temp\\ipykernel_22576\\593233457.py:9: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(i)\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert '52.0' with type str: tried to convert to double\", 'Conversion failed for column CODUFNATU with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(i)\n\u001b[1;32m---> 10\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_parquet(i[:\u001b[38;5;241m68\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3034\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3115\u001b[0m     path,\n\u001b[0;32m   3116\u001b[0m     engine,\n\u001b[0;32m   3117\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3118\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3119\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3120\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3122\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m    483\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    484\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    485\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    486\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    487\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parquet.py:190\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 190\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    193\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\table.pxi:3869\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:626\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m--> 626\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m maybe_fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    628\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:600\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    596\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    597\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    598\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    599\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[0;32m    604\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:594\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    591\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 594\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray(col, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_, from_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe\u001b[38;5;241m=\u001b[39msafe)\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    596\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    597\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    598\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    599\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\array.pxi:340\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\array.pxi:86\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: (\"Could not convert '52.0' with type str: tried to convert to double\", 'Conversion failed for column CODUFNATU with type object')"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a.append('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2012.csv')\n",
    "a.append('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2015.csv')\n",
    "a.append('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2016.csv')\n",
    "a.append('D:\\\\_repositories\\\\Aggregation\\\\Results\\\\SINASC - Dtype Corrigido\\\\DN2017.csv')\n",
    "\n",
    "for i in a:\n",
    "    df = pd.read_csv(i)\n",
    "    df.to_parquet(i[:68] + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
