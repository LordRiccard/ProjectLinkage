{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path, pattern):\n",
    "    files = glob.glob(f'{path}/{pattern}')\n",
    "    # print(files)\n",
    "    # print(len(files))\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a column called index in the dataframe\n",
    "# this column will have the format:\n",
    "# prefix + 0000001 (Ex. 310.000.001) to prefix + length of dataframe (Ex. 312.123.942)\n",
    "\n",
    "def add_index(df, prefix):\n",
    "    size = len(df)\n",
    "    prefix = prefix * 10**len(str(size)) + 1\n",
    "\n",
    "    df['index'] = range(prefix, prefix + size)\n",
    "    df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_delete(df, list_columns):\n",
    "    for item in list_columns:\n",
    "        if item in df.columns:\n",
    "            df = df.drop(item, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = find_files('D:\\\\_repositories\\\\Aggregation\\\\SIH\\\\3. Concatenado', '*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('results/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results\\\\RD2012.parquet',\n",
       " 'results\\\\RD2013.parquet',\n",
       " 'results\\\\RD2014.parquet',\n",
       " 'results\\\\RD2015.parquet',\n",
       " 'results\\\\RD2016.parquet',\n",
       " 'results\\\\RD2017.parquet',\n",
       " 'results\\\\RD2018.parquet',\n",
       " 'results\\\\RD2019.parquet',\n",
       " 'results\\\\RD2020.parquet',\n",
       " 'results\\\\RD2021.parquet',\n",
       " 'results\\\\RD2022.parquet']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the index, and treats the dtype warning to successfully corvert to parquet\n",
    "\n",
    "inicial_ano = 12 # ano em processamento\n",
    "\n",
    "for item in files:\n",
    "    df = pd.read_parquet(item)\n",
    "\n",
    "    # Index\n",
    "    add_index(df, int('3' + str(inicial_ano)))\n",
    "\n",
    "    # Deleting past index columns\n",
    "    df = safe_delete(df, ['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "\n",
    "    # Saving to parquet\n",
    "    df.to_parquet(f'final shape/RD20{inicial_ano}.parquet')\n",
    "    inicial_ano += 1\n",
    "\n",
    "    # Memory safety\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('results/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results\\\\RD2012.parquet',\n",
       " 'results\\\\RD2013.parquet',\n",
       " 'results\\\\RD2014.parquet',\n",
       " 'results\\\\RD2015.parquet',\n",
       " 'results\\\\RD2016.parquet',\n",
       " 'results\\\\RD2017.parquet',\n",
       " 'results\\\\RD2018.parquet',\n",
       " 'results\\\\RD2019.parquet',\n",
       " 'results\\\\RD2020.parquet',\n",
       " 'results\\\\RD2021.parquet',\n",
       " 'results\\\\RD2022.parquet']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384084610 - 0\n",
      "2714527792 - 0\n",
      "3766512573 - 0\n",
      "3409573112 - 0\n",
      "3384043318 - 0\n",
      "3347896289 - 0\n",
      "3483350150 - 0\n",
      "3018110962 - 0\n",
      "3039705103 - 0\n",
      "3216779181 - 0\n",
      "3530272864 - 0\n"
     ]
    }
   ],
   "source": [
    "for item in files:\n",
    "    df = pd.read_parquet(item)\n",
    "    print(f'{df.memory_usage().sum()} - {df.duplicated().sum()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
